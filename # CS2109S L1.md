# CS2109S L1
##  What is ai
Intelligent Agents: A rational agent wil choose the action which maximize the outcome
Agent   <-percepts  
Sensors				Environment
Function
Actuators  ->actions
## Properties of Task Environment
* Fully obversable vs Partially obversable
* Deterministic vs Stochastic
	The next state of the environment is completely determined by the current state and the action executed by the agent/ The environment is also dependent on the action of other agents, then it is also strategic (unless the other agents are predictable)
* Episodic vs Sequential
	The agent's experience is divided into atoimc "episodes" ,and the choice of action in each episode depends onku on the episode itself./Sequential means the previous action affects now situation.
* Static/Dynamic
	The environment is unchanged while agent is deliberating
	The environment is semi-dynamic if the environment itself does not change with the passage with the passage of time, but the agent's performance scores does.
* Discrete vs Continuous
	A limited number of distinct, clearly defined percepts and actions.
* Single agent/ multi agent
## The agent function
The agent function maps from percept histories to action
* Simple reflex agent(reflex simply based on the situation)
* Goal-based Agent
* Utility-based Agent
* Learning Agent
## Exploration vs Exploitation
## How to build an agent
### Search problems
The goal is to find a state  from a set of possible states by exploring various possibilities
To solve such problems ,we need
* A goal
* A model of the environment
* A search algorythm   
---
# L2 Search
## 1.Search Terms:
Search Tree
Path Cost:The cost of a paath from any state to any state
OPtimal path cost : the cost of the lowest-cost from any state to any state
## Evaluation criteria
1. Complexity:
Time Complexity: number of nodes generated or expanded
Spaace Complexity: max number of node in memory

2. Completeness and Optimality:
Complete:An algoryth, is complete if for every problem instance . it will find a solution if it exist
Optimal : If produce a solution, the solution is the best possible
## Uninformed search
* BFS:use a queue to maintain the frontier
	Time complexity: exponential
	Space: exponential
	Complete: exponential
	Optimal: If all cost is the same
* Uniform-cost search(UCS) : use a priority queue
	Time : exponential(tier)
	Space: exponential(size of tier)
	Complete: yes
	Optimal: yes
* DFS :
	Time: Exponential
	Space: Polynomial
	Complete: NO, when the depth is infinite(e.g. reversible)
	Optimal: No, may exist more shallow solution
## Heuristic
A heuristic is an estimate of the optimal path cost from ant state to the goal state

* $A *  search: f(n) = g(n) + h(n)
  g is the cost to reach n, h is the heuristic from n to goal
	Time: exponential
	Space(frontier): exponential
    Complete: Yes if edge cost is positive and branch in finite
    Optimal: Depends on the heuristic
* Admissible Heuristic
* A heurisitc h(n) is admissible if fir every node n, h(n) <= h * (n) , which is the optimal path cost to reach the goal state from n
* Theorem: A * search is optimal with admissible heuristic without visited memory is optimal
* Consistent Heurisitc: for every node n . every successor n' of n generated by any action a, h(n)<=c(n,a,n') + h(n'), and h(G) = 0.
* Theorem :A * search is optimal with consistent heuristic with visited memory is optimal
* Dominance: if h1(n) >= h2(n),then h1 dominates h2, h1 is better for search if admissible
## Search strategy:
* Depth limited Search(DLS): Limit te=he search to depth L, Backtrack when the limit is hit
Time : exponential
Space: polynomial
Complete: No
Optimal: No
* Iterative Deepening Search: Search with depth limit 0,.....
Time : exponential
Space: polynomial
Complete: Yes
Optimal: Yes
*
---
# L3
## 1. Systematic/Local Search
Local Search:
* Only locallu reachable states
* typically incomplete and suboptimal
* Anytime property: longer runtime, better solution

Problem formulation in local search
* State : Represent different configurations of candidate solutions, may or may not map to an actual problem state, but are used to represenet potential solutions
* Initial State: Starting configuration
* Goal Test: CHeck if it is the desired solution
* Successor function:Generate neighbor states by applying modifications
*

Evaluation function:
A mathematical function used to access the quality or desirability of a state
e.g. in n queens problem, can be the number of safe queens

State Space Landscape
* Global maximum: The overal hifhest point or sollution across the entire state sapce that represents optimal solution
* Local Maximum: A point tn the state space that is higher than its immediate nerghbors, nut there may be higher values globally
*

## 2. Adversarial Search
Adverarial games: one player's gain is the other player's loss

Problem Formulatuon:
States
INitial State
Terminal States:: state where the game ends
Actions
Transition
Utility Functiobn:
output the value of a staet from the perspective of our agent

Minimax
Algorithm fro two-plaer zero-sum game
core assumption: all players play optimally
expand function : expland(state)
for each state , compute next_state = transition(state, action)
Terminal function: return is is terminal
untility function: return the score of the agent

Theorem : In any finite , two-player , zero sum game of perfect information, the minimax algorith, comoputes the optimal strategy for both playerz , guaranteeing th ebest achievable outcome ofr each, assuming both play optimally

Theorem: If PLayer A' opponent deviaates from optimal play (plays sub-optimally), then for any action taken by player A, the utility obtained by player A is never less than the utility they would obtain against an optimal opponent

Alpha-Beta pruning:
Maintain the best outcomes so far for player A and Player B:
	Highest value for A for player A, lowest value for A for player B
